\chapter{ЕКСПЕРИМЕНТАЛЬНІ ДОСЛІДЖЕННЯ}
Ми оцінюємо можливості репрезентативного навчання
ResNet, Vision Transformer (ViT) та гібриду.
Щоб зрозуміти вимоги до даних кожної моделі, ми попередньо
тренуємось на наборах даних різного розміру та оцінюємо багато
контрольних завдань. Розглядаючи обчислювальні витрати на
попереднє тренування моделі, ViT працює дуже вигідно,
досягаючи кращих методів за більшістю тестів розпізнавання
за нижчої вартості попереднього тренування. Нарешті, ми проводимо
невеликий експеримент, використовуючи самоконтроль,
і показуємо, що самоувага ViT є перспективною.

\section{Налаштування}
\subsection{Датасети}
Для дослідження масштабованості моделі ми використовуємо
набір даних ILSVRC-2012 ImageNet з 1 тис. класами та 1,3 млн. зображеннями
(далі ми називаємо його ImageNet), його надмножину ImageNet-21k
з 21 тис. класами та 14 млн. зображеннями та JFT з 18 тис. 
класів та 303 млн. зображень із високою роздільною здатністю.
Ми видаляємо дублікати даних попередньої підготовки
відносно тестових наборів даних поточних завдань.
Ми переносимо моделі, навчені цим набором даних, на кілька базових завдань:
ImageNet на оригінальних мітках перевірки та очищених мітках ReaL,
CIFAR-10/100, Oxford-IIIT Pets та Oxford Flowers-102.

\subsection{Варіанти моделі}
Ми базуємо конфігурації ViT на тих, що використовуються для
BERT \cite{bert}, як описано в таблиці \ref{tab:t1}.
Моделі ``Base'' та ``Large'' безпосередньо беруться від BERT,
і ми додаємо більшу модель ``Huge''. Далі ми використовуємо
короткі позначення для позначення розміру моделі
та розміру вхідного регіону: наприклад, ViT-L/16 означає ``Large''
варіант із розміром вхідного патча $16 \times 16$.
Зауважте, що довжина послідовності трансформера
обернено пропорційна квадрату розміру регіона,
тому моделі з меншим розміром патча обчислювально дорожчі.

Для базових CNN ми використовуємо ResNet,
але замінюємо шари пакетної нормалізації
на групову нормалізацію і використовуємо стандартизовані згортки.
Для гібридів ми подаємо проміжні репрезентації у ViT з
розміром регіона один ``піксель''.

\begin{table}[H]
    \caption{Деталі варіантів моделі}
    \begin{tabular}{ c c c c c c }
        \hline
        Модель & Шари & Прихов. розмір $D$ & Розм. щільн. шару & Голов. & Парам.  \\ \hline
        ViT-Base & 12 & 768 & 3072 & 12 & 86M  \\ 
        ViT-Large & 24 & 1024 & 4096 & 16 & 307M  \\ 
        ViT-Huge & 32 & 1280 & 5120 & 16 & 632M  \\ \hline
    \end{tabular}
    \label{tab:t1}
\end{table}

\subsection{Навчання та точне налагодження}
Ми тренуємо всі моделі, включаючи ResNet, за допомогою Adam
з $\beta_1 = 0.9$,$\beta_2 = 0.999$, пеакетний розмір 4096 та вагою розпаду
$0.1$. Для точкого налагодженн ми використовуємо SGD з імпульсом,
розмір пакету 512, для всіх моделей.
