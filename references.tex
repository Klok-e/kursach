\renewcommand\bibname{ПЕРЕЛІК ДЖЕРЕЛ ПОСИЛАННЯ}
\begin{thebibliography}{9}
    \bibitem{attention}
    Weng L. Attention? Attention! [Електронний ресурс] / Lilian Weng // lilianweng.github.io/lil-log. – 2018. – Режим доступу до ресурсу: http://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html.

    \bibitem{cortex-stuff}
    Hubel D. Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex / D. Hubel, T. Wiesel. // The Journal of physiology. – 1962. – С. 106–154.

    \bibitem{cortex-equations}
    Hodgkin A. quantitative description of membrane current and its application to conduction and excitation in nerve / A. Hodgkin, A. Huxley. // The Journal of physiology. – 1952. – С. 500–544.

    \bibitem{rozenblatt}
    Rosenblatt F. The perceptron, a perceiving and recognizing automaton Project Para / Frank Rosenblatt. // Cornell Aeronautical Laboratory. – 1957.

    \bibitem{nn:peyre}
    Peyré G. Mathematics of Neural Networks [Електронний ресурс] / Gabriel Peyré – Режим доступу до ресурсу: https://mathematical-tours.github.io/book-basics-sources/neural-networks-en/NeuralNetworksEN.pdf.

    \bibitem{nn:backpropagation}
    Rumelhart D. Learning representations by back-propagating errors / D. Rumelhart, G. Hinton, R. Williams. // nature. – 1986. – С. 533–536.

    \bibitem{gradient-descend}
    Ruder S. An overview of gradient descent optimization algorithms / Sebastian Ruder. // arXiv preprint arXiv:1609.04747. – 2016.

    \bibitem{nn:multilayer-perceptrons}
    Grosse R. Lecture 5: Multilayer Perceptrons [Електронний ресурс] / Roger Grosse – Режим доступу до ресурсу: https://www.cs.toronto.edu/~mren/teach/csc411\_19s/lec/lec10\_notes1.pdf.

    \bibitem{nn:recurrent-hard}
    Bengio Y. Learning long-term dependencies with gradient descent is difficult / Y. Bengio, P. Simard, P. Frasconi. // IEEE Transactions on Neural Networks. – 1994. – С. 157–166.
    
    \bibitem{nn:lstm}
    Hochreiter S. Long Short-term Memory / S. Hochreiter, J. Schmidhuber. // Neural computation. – 1997. – С. 1735–80.

    \bibitem{nn:gru}
    Cho K. On the Properties of Neural Machine Translation: Encoder–Decoder Approaches / K. Cho, B. van Merri ̈enboer, D. Bahdanau. // arXiv preprint arXiv:1409.1259. – 2014.

    \bibitem{nn:cnn-rnn}
    CNN-RNN: A Unified Framework for Multi-label Image Classification / [J. Wang, Y. Yang, J. Mao та ін.]. // arXiv:1604.04573. – 2016. – С. 2285–2294.

    \bibitem{nn:seq2seq}
    Sutskever I. Sequence to Sequence Learningwith Neural Networks / I. Sutskever, O. Vinyals, Q. V. Le. // arXiv:1409.3215. – 2014.

    \bibitem{nn:attention}
    Bahdanau D. Neural Machine Translation by Jointly Learning to Align and Translate / D. Bahdanau, K. Cho, Y. Bengio. // arXiv:1409.0473. – 2014.
\end{thebibliography}